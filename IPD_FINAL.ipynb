{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXlkBVW6QvYEH8ThSYZ3q9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivhub09/IPD25/blob/main/IPD_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4lMjWXG0qgI",
        "outputId": "e93ff772-573f-4779-b1fc-8a18401e3f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72f1wzpi3La4",
        "outputId": "064e2d71-29ec-4914-b9b6-86e4112a2e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/239.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/239.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m235.5/239.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.10.0)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Define number of topics\n",
        "num_topics = 5\n",
        "\n",
        "# Preprocess and vectorize documents\n",
        "vectorizer = TfidfVectorizer(max_features=2000)\n",
        "document_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Fit the LDA model\n",
        "lda = LatentDirichletAllocation(n_components=num_topics, random_state=0)\n",
        "lda.fit(document_matrix)\n",
        "\n",
        "# Get topics\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "  print(\"Topic\", topic_idx + 1, \":\")\n",
        "  print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ7GGpsTTGVG",
        "outputId": "b05c8398-99ce-46c6-cab3-081afa9103d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1 :\n",
            "['mahesh', 'agreement', 'details', 'of', 'and', 'between', 'deal', 'is', 'shivam', 'the']\n",
            "\n",
            "\n",
            "Topic 2 :\n",
            "['agreement', 'details', 'of', 'the', 'and', 'between', 'deal', 'is', 'shivam', 'anish']\n",
            "\n",
            "\n",
            "Topic 3 :\n",
            "['details', 'of', 'and', 'between', 'deal', 'is', 'shivam', 'the', 'further', 'information']\n",
            "\n",
            "\n",
            "Topic 4 :\n",
            "['details', 'of', 'and', 'between', 'deal', 'is', 'shivam', 'the', 'concluding', 'remarks']\n",
            "\n",
            "\n",
            "Topic 5 :\n",
            "['and', 'between', 'deal', 'is', 'shivam', 'mahesh', 'agreement', 'details', 'of', 'the']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Define number of topics\n",
        "num_topics = 5\n",
        "\n",
        "# Preprocess and vectorize documents (This part remains the same)\n",
        "# ... your preprocessing and vectorization code here ...\n",
        "\n",
        "# Fit the LDA model\n",
        "lda = LatentDirichletAllocation(n_components=num_topics)\n",
        "lda.fit(document_matrix)\n",
        "\n",
        "# Get topics\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "  print(\"Topic\", topic_idx + 1, \":\")\n",
        "  print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9QVxQkBTx-x",
        "outputId": "d69bd699-65eb-4ab7-80b2-43d1ba085ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1 :\n",
            "['mahesh', 'agreement', 'details', 'of', 'and', 'between', 'deal', 'is', 'shivam', 'the']\n",
            "\n",
            "\n",
            "Topic 2 :\n",
            "['agreement', 'details', 'of', 'the', 'and', 'between', 'deal', 'is', 'shivam', 'anish']\n",
            "\n",
            "\n",
            "Topic 3 :\n",
            "['details', 'of', 'and', 'between', 'deal', 'is', 'shivam', 'the', 'further', 'information']\n",
            "\n",
            "\n",
            "Topic 4 :\n",
            "['details', 'of', 'and', 'between', 'deal', 'is', 'shivam', 'the', 'concluding', 'remarks']\n",
            "\n",
            "\n",
            "Topic 5 :\n",
            "['and', 'between', 'deal', 'is', 'shivam', 'mahesh', 'agreement', 'details', 'of', 'the']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def umass_coherence(doc_word_matrix, word_id_dict, topics):\n",
        "  \"\"\"\n",
        "  Calculates Umass coherence score for LDA model\n",
        "\n",
        "  Args:\n",
        "      doc_word_matrix: Document-word matrix (sparse matrix)\n",
        "      word_id_dict: Dictionary mapping word IDs to words\n",
        "      topics: LDA model topics\n",
        "\n",
        "  Returns:\n",
        "      Umass coherence score\n",
        "  \"\"\"\n",
        "  eps = 1e-12\n",
        "  coherence = 0.0\n",
        "  _, vocab_size = doc_word_matrix.shape\n",
        "\n",
        "  for m, x in enumerate(topics):\n",
        "    cluster_sum = np.sum(x)\n",
        "    # Iterate over non-zero elements of the document vectors efficiently\n",
        "    for i, j, v in zip(doc_word_matrix.indptr[:-1], doc_word_matrix.indices, doc_word_matrix.data):\n",
        "      if x[j] > 0:  # Check if word is present in the topic\n",
        "        coherence += v / (cluster_sum + eps)\n",
        "  coherence /= (vocab_size * (vocab_size - 1))\n",
        "  return coherence\n",
        "\n",
        "# Function to find the optimal number of topics using custom coherence\n",
        "def find_optimal_num_topics(documents, max_topics=10):\n",
        "  vectorizer = TfidfVectorizer(max_features=2000)\n",
        "  document_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "  coherence_values = []\n",
        "  for num_topics in range(2, max_topics + 1):\n",
        "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=0)\n",
        "    lda.fit(document_matrix)\n",
        "    topics = lda.components_\n",
        "    coherence_values.append(umass_coherence(document_matrix, vectorizer.get_feature_names_out(), topics))\n",
        "\n",
        "  optimal_num_topics = np.argmax(coherence_values) + 2  # Adding 2 because the loop starts from 2\n",
        "  return optimal_num_topics\n",
        "\n",
        "# Sample input: List of pages in a document\n",
        "documents = [\n",
        "  \"The deal is between Shivam and Anish.\",\n",
        "  \"The deal is between Shivam and Mahesh.\",\n",
        "  \"Concluding remarks...\"\n",
        "]\n",
        "\n",
        "# Find the optimal number of topics\n",
        "optimal_num_topics = find_optimal_num_topics(documents)\n",
        "print(\"Optimal Number of Topics:\", optimal_num_topics)\n",
        "\n",
        "# Fit the LDA model with the optimal number of topics\n",
        "vectorizer = TfidfVectorizer(max_features=2000)\n",
        "document_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=optimal_num_topics, random_state=0)\n",
        "lda.fit(document_matrix)\n",
        "\n",
        "# Get topics\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "  print(\"Topic\", topic_idx + 1, \":\")\n",
        "  print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n",
        "  print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm4q4ILF0-gw",
        "outputId": "e200e567-a0ca-499d-8f26-cdb14efb5064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Number of Topics: 10\n",
            "Topic 1 :\n",
            "['concluding', 'remarks', 'anish', 'and', 'between', 'deal', 'is', 'shivam', 'the', 'mahesh']\n",
            "\n",
            "\n",
            "Topic 2 :\n",
            "['anish', 'mahesh', 'and', 'between', 'deal', 'is', 'shivam', 'the', 'concluding', 'remarks']\n",
            "\n",
            "\n",
            "Topic 3 :\n",
            "['concluding', 'remarks', 'mahesh', 'deal', 'is', 'and', 'between', 'shivam', 'the', 'anish']\n",
            "\n",
            "\n",
            "Topic 4 :\n",
            "['concluding', 'remarks', 'anish', 'mahesh', 'and', 'between', 'deal', 'is', 'shivam', 'the']\n",
            "\n",
            "\n",
            "Topic 5 :\n",
            "['concluding', 'remarks', 'anish', 'mahesh', 'and', 'between', 'deal', 'is', 'shivam', 'the']\n",
            "\n",
            "\n",
            "Topic 6 :\n",
            "['concluding', 'remarks', 'anish', 'mahesh', 'and', 'between', 'deal', 'is', 'shivam', 'the']\n",
            "\n",
            "\n",
            "Topic 7 :\n",
            "['concluding', 'remarks', 'anish', 'mahesh', 'and', 'between', 'deal', 'is', 'shivam', 'the']\n",
            "\n",
            "\n",
            "Topic 8 :\n",
            "['concluding', 'remarks', 'anish', 'mahesh', 'and', 'between', 'deal', 'is', 'shivam', 'the']\n",
            "\n",
            "\n",
            "Topic 9 :\n",
            "['concluding', 'remarks', 'anish', 'mahesh', 'and', 'between', 'deal', 'is', 'shivam', 'the']\n",
            "\n",
            "\n",
            "Topic 10 :\n",
            "['concluding', 'remarks', 'anish', 'mahesh', 'and', 'between', 'deal', 'is', 'shivam', 'the']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def umass_coherence(doc_word_matrix, word_id_dict, topics):\n",
        "  \"\"\"\n",
        "  Calculates Umass coherence score for LDA model\n",
        "\n",
        "  Args:\n",
        "      doc_word_matrix: Document-word matrix (sparse matrix)\n",
        "      word_id_dict: Dictionary mapping word IDs to words\n",
        "      topics: LDA model topics\n",
        "\n",
        "  Returns:\n",
        "      Umass coherence score\n",
        "  \"\"\"\n",
        "  eps = 1e-12\n",
        "  coherence = 0.0\n",
        "  _, vocab_size = doc_word_matrix.shape\n",
        "\n",
        "  for m, x in enumerate(topics):\n",
        "    cluster_sum = np.sum(x)\n",
        "    # Iterate over non-zero elements of the document vectors efficiently\n",
        "    for i, j, v in zip(doc_word_matrix.indptr[:-1], doc_word_matrix.indices, doc_word_matrix.data):\n",
        "      if x[j] > 0:  # Check if word is present in the topic\n",
        "        coherence += v / (cluster_sum + eps)\n",
        "  coherence /= (vocab_size * (vocab_size - 1))\n",
        "  return coherence\n",
        "\n",
        "def check_and_merge_topics(topics, threshold=0.9):\n",
        "  \"\"\"\n",
        "  Checks for highly similar topics and merges them\n",
        "\n",
        "  Args:\n",
        "      topics: List of LDA topics (each topic is a word distribution)\n",
        "      threshold: Similarity threshold (0 to 1) for merging\n",
        "\n",
        "  Returns:\n",
        "      List of merged topics\n",
        "  \"\"\"\n",
        "  merged_topics = []\n",
        "  seen_topics = set()\n",
        "  for topic in topics:\n",
        "    most_similar_topic = None\n",
        "    max_similarity = 0\n",
        "    for seen_topic in seen_topics:\n",
        "      similarity = np.dot(topic, seen_topic) / (np.linalg.norm(topic) * np.linalg.norm(seen_topic))\n",
        "      if similarity > max_similarity:\n",
        "        max_similarity = similarity\n",
        "        most_similar_topic = seen_topic\n",
        "    if max_similarity < threshold:\n",
        "      merged_topics.append(topic)\n",
        "      seen_topics.add(tuple(topic))  # Convert topic to hashable tuple for set\n",
        "    else:\n",
        "      # Skip adding similar topic (already merged)\n",
        "      pass\n",
        "  return merged_topics\n",
        "\n",
        "# Function to find the optimal number of topics using custom coherence\n",
        "def find_optimal_num_topics(documents, max_topics=100):\n",
        "  vectorizer = TfidfVectorizer(max_features=2000)\n",
        "  document_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "  coherence_values = []\n",
        "  for num_topics in range(2, max_topics + 1):\n",
        "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=0)\n",
        "    lda.fit(document_matrix)\n",
        "    topics = lda.components_\n",
        "    coherence_values.append(umass_coherence(document_matrix, vectorizer.get_feature_names_out(), topics))\n",
        "\n",
        "  optimal_num_topics = np.argmax(coherence_values) + 2  # Adding 2 because the loop starts from 2\n",
        "  return optimal_num_topics\n",
        "\n",
        "# Sample input: List of pages in a document\n",
        "documents = [\n",
        "  \"The deal is between Shivam and Anish.\",\n",
        "  \"Details of the agreement...\",\n",
        "  \"Further information...\",\n",
        "  \"The deal is between Shivam and Mahesh.\",\n",
        "  \"Concluding remarks...\"\n",
        "]\n",
        "\n",
        "# Find the optimal number of topics\n",
        "optimal_num_topics = find_optimal_num_topics(documents)\n",
        "print(\"Optimal Number of Topics:\", optimal_num_topics)\n",
        "\n",
        "# Fit the LDA model with the optimal number of topics\n",
        "vectorizer = TfidfVectorizer(max_features=2000)\n",
        "document_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=optimal_num_topics, random_state=0)\n",
        "lda.fit(document_matrix)\n",
        "topics = lda.components_\n",
        "\n",
        "# Check and merge similar topics (optional, adjust threshold as needed)\n",
        "merged_topics = check_and_merge_topics(topics, threshold=0.9)\n",
        "\n",
        "# Get topics (merged or original)\n",
        "for topic_idx, topic in enumerate(merged_topics):\n",
        "  print(\"Topic\", topic_idx + 1, \":\")\n",
        "  print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n",
        "  print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qC4SdlT1txL",
        "outputId": "ea10c37a-519c-41c6-ba2a-9cd1fd98ed6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Number of Topics: 100\n",
            "Topic 1 :\n",
            "['information', 'of', 'remarks', 'the', 'and', 'between', 'deal', 'is', 'shivam', 'mahesh']\n",
            "\n",
            "\n",
            "Topic 2 :\n",
            "['deal', 'details', 'further', 'information', 'is', 'mahesh', 'of', 'remarks', 'shivam', 'the']\n",
            "\n",
            "\n",
            "Topic 3 :\n",
            "['deal', 'details', 'is', 'mahesh', 'of', 'remarks', 'shivam', 'the', 'further', 'information']\n",
            "\n",
            "\n",
            "Topic 4 :\n",
            "['mahesh', 'of', 'remarks', 'the', 'and', 'between', 'deal', 'is', 'shivam', 'anish']\n",
            "\n",
            "\n",
            "Topic 5 :\n",
            "['details', 'further', 'information', 'is', 'mahesh', 'of', 'shivam', 'the', 'concluding', 'remarks']\n",
            "\n",
            "\n",
            "Topic 6 :\n",
            "['further', 'information', 'is', 'mahesh', 'remarks', 'shivam', 'the', 'agreement', 'details', 'of']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_num_topics = find_optimal_num_topics(sentences)\n",
        "print(\"Optimal Number of Topics:\", optimal_num_topics)\n",
        "\n",
        "# Fit the LDA model with the optimal number of topics\n",
        "vectorizer = TfidfVectorizer(max_features=2000)\n",
        "document_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=optimal_num_topics, random_state=0)\n",
        "lda.fit(document_matrix)\n",
        "topics = lda.components_\n",
        "\n",
        "# Check and merge similar topics (optional, adjust threshold as needed)\n",
        "merged_topics = check_and_merge_topics(topics, threshold=0.9)\n",
        "\n",
        "# Get topics (merged or original)\n",
        "for topic_idx, topic in enumerate(merged_topics):\n",
        "  print(\"Topic\", topic_idx + 1, \":\")\n",
        "  print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n",
        "  print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM3hmkiS3R-e",
        "outputId": "b677de35-7c9c-47a4-9581-14cdcce2031a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Number of Topics: 100\n",
            "Topic 1 :\n",
            "['following', 'for', 'from', 'full', 'funds', 'galinato', 'geraldine', 'grace', 'day', 'your']\n",
            "\n",
            "\n",
            "Topic 2 :\n",
            "['notice', 'day', 'amount', 'the', 'cash', 'due', 'required', 'notified', 'be', 'will']\n",
            "\n",
            "\n",
            "Topic 3 :\n",
            "['their', 'talon', 'commencing', 'dwelling', 'and', 'may', 'at', 'day', '20th', 'the']\n",
            "\n",
            "\n",
            "Topic 4 :\n",
            "['mary', 'herein', '2006', 'malate', 'egi', 'unit', 'tower', '2339', 'taft', 'and']\n",
            "\n",
            "\n",
            "Topic 5 :\n",
            "['following', 'for', 'from', 'full', 'funds', 'grace', 'day', 'your', 'galinato', 'geraldine']\n",
            "\n",
            "\n",
            "Topic 6 :\n",
            "['for', 'from', 'full', 'funds', 'galinato', 'geraldine', 'expense', 'ingles', 'levy', 'antonio']\n",
            "\n",
            "\n",
            "Topic 7 :\n",
            "['for', 'from', 'full', 'funds', 'galinato', 'geraldine', 'expense', 'rental', 'house', 'contract']\n",
            "\n",
            "\n",
            "Topic 8 :\n",
            "['month', 'within', 'grace', 'per', 'to', 'subject', 'percent', 'penalty', 'interest', 'delay']\n",
            "\n",
            "\n",
            "Topic 9 :\n",
            "['method', 'initial', 'days', 'before', 'least', 'moving', 'under', 'in', 'of', 'payment']\n",
            "\n",
            "\n",
            "Topic 10 :\n",
            "['hereby', 'terms', 'consideration', 'to', 'following', 'them', 'above', 'permitting', 'property', 'occupy']\n",
            "\n",
            "\n",
            "Topic 11 :\n",
            "['in', 'resident', 'as', 'known', 'the', 'consideration', 'galinato', 'geraldine', 'of', 'agreements']\n",
            "\n",
            "\n",
            "Topic 12 :\n",
            "['from', 'full', 'funds', 'evict', 'be', 'will', 'not', 'checks', 'returned', 'redeposited']\n",
            "\n",
            "\n",
            "Topic 13 :\n",
            "['funds', 'galinato', 'failure', 'your', 'by', 'known', 'all', 'men', 'presents', 'these']\n",
            "\n",
            "\n",
            "Topic 14 :\n",
            "['contract', '20th', 'house', 'made', '2007', 'between', 'entered', 'into', 'and', 'this']\n",
            "\n",
            "\n",
            "Topic 15 :\n",
            "['be', 'will', 'period', 'for', 'payment', 'late', 'grace', 'allowed', 'dav', 'three']\n",
            "\n",
            "\n",
            "Topic 16 :\n",
            "['pesos', 'hundred', 'secure', 'pledge', 'full', 'compliance', 'to', 'deposit', 'of', 'resident']\n",
            "\n",
            "\n",
            "Topic 17 :\n",
            "['expense', 'any', 'funds', 'replaced', 'be', 'at', 'will', 'deposit', 'the', 'or']\n",
            "\n",
            "\n",
            "Topic 18 :\n",
            "['tenancy', 'end', 'served', 'on', 'being', 'residential', 'result', 'pay', 'to', 'failure']\n",
            "\n",
            "\n",
            "Topic 19 :\n",
            "['full', 'and', 'is', 'jr', 'check', 'until', 'unpaid', 'returned', 'first', 'dishonored']\n",
            "\n",
            "\n",
            "Topic 20 :\n",
            "['the', 'have', 'all', 'you', 'residential', 'prescribed', 'to', 'once', 'overdue', 'received']\n",
            "\n",
            "\n",
            "Topic 21 :\n",
            "['your', 'served', 'balance', 'being', 'late', 'regardless', 'paying', 'owed', 'habitually', 'also']\n",
            "\n",
            "\n",
            "Topic 22 :\n",
            "['premises', 'immediate', 'shall', 'action', 'habitual', 'seize', 'evict', 'taking', 'resident', 'the']\n",
            "\n",
            "\n",
            "Topic 23 :\n",
            "['herein', 'metro', 'las', 'age', 'referred', 'road', 'village', 'pilar', 'manganese', 'and']\n",
            "\n",
            "\n",
            "Topic 24 :\n",
            "['from', 'failure', 'your', 'served', 'you', 'have', 'balance', 'an', 'outstanding', 'if']\n",
            "\n",
            "\n",
            "Topic 25 :\n",
            "['by', 'may', 'deposit', 'tenancy', 'not', 'used', 'note', 'during', 'tenant', 'the']\n",
            "\n",
            "\n",
            "Topic 26 :\n",
            "['may', 'other', 'check', 'regardless', 'payments', 'made', 'additional', 'cause', 'afterwards', 'no']\n",
            "\n",
            "\n",
            "Topic 27 :\n",
            "['payable', 'advance', 'six', 'thousand', 'hundred', 'of', 'ip', 'sum', 'every', 'month']\n",
            "\n",
            "\n",
            "Topic 28 :\n",
            "['antonio', 'monthly', 'checks', 'thereafter', 'payments', 'payable', 'paid', 'post', 'dated', 'must']\n",
            "\n",
            "\n",
            "Topic 29 :\n",
            "['deposit', 'dwelling', 'during', 'the', 'as', 'ingles', 'owner', 'levy', 'known', 'antonio']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENCHANCED CODE"
      ],
      "metadata": {
        "id": "l48yhA8Q54Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "def clean_and_normalize_text(text):\n",
        "    # Remove punctuation and convert to lowercase\n",
        "    text = ''.join([char.lower() for char in text if char.isalnum() or char.isspace()])\n",
        "\n",
        "    # Apply lemmatization using NLTK's WordNet Lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "def umass_coherence(doc_word_matrix, word_id_dict, topics):\n",
        "  print(\"umass coherence\")\n",
        "  \"\"\"\n",
        "  Calculates Umass coherence score for LDA model\n",
        "\n",
        "  Args:\n",
        "      doc_word_matrix: Document-word matrix (sparse matrix)\n",
        "      word_id_dict: Dictionary mapping word IDs to words\n",
        "      topics: LDA model topics\n",
        "\n",
        "  Returns:\n",
        "      Umass coherence score\n",
        "  \"\"\"\n",
        "  eps = 1e-12\n",
        "  coherence = 0.0\n",
        "  _, vocab_size = doc_word_matrix.shape\n",
        "\n",
        "  for m, x in enumerate(topics):\n",
        "    cluster_sum = np.sum(x)\n",
        "    # Iterate over non-zero elements of the document vectors efficiently\n",
        "    for i, j, v in zip(doc_word_matrix.indptr[:-1], doc_word_matrix.indices, doc_word_matrix.data):\n",
        "      if x[j] > 0:  # Check if word is present in the topic\n",
        "        coherence += v / (cluster_sum + eps)\n",
        "  coherence /= (vocab_size * (vocab_size - 1))\n",
        "  return coherence\n",
        "\n",
        "\n",
        "def customize_tfidf_vectorizer(documents):\n",
        "    print(\"Cleaning documents\")\n",
        "    # Clean and normalize text in documents\n",
        "    cleaned_documents = [clean_and_normalize_text(doc) for doc in documents]\n",
        "\n",
        "    # Tokenize the cleaned documents\n",
        "    tokenized_documents = [word_tokenize(doc) for doc in cleaned_documents]\n",
        "\n",
        "    # Customize TfidfVectorizer\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        max_features=2000,\n",
        "        stop_words=list(ENGLISH_STOP_WORDS),  # Convert to list\n",
        "        ngram_range=(1, 2),  # Experiment with bigrams\n",
        "        min_df=2,  # Filter infrequent terms\n",
        "        max_df=0.95,  # Filter overly frequent terms\n",
        "        sublinear_tf=True  # Downweigh frequent terms\n",
        "    )\n",
        "\n",
        "    document_matrix = vectorizer.fit_transform(cleaned_documents)\n",
        "    return document_matrix, vectorizer, tokenized_documents  # Return tokenized_documents\n",
        "\n",
        "# ... (rest of the code remains unchanged)\n",
        "\n",
        "\n",
        "def check_and_merge_topics(topics, threshold=0.9):\n",
        "  print(\"Checking and removing duplicate topics\")\n",
        "  \"\"\"\n",
        "  Checks for highly similar topics and merges them\n",
        "\n",
        "  Args:\n",
        "      topics: List of LDA topics (each topic is a word distribution)\n",
        "      threshold: Similarity threshold (0 to 1) for merging\n",
        "\n",
        "  Returns:\n",
        "      List of merged topics\n",
        "  \"\"\"\n",
        "  merged_topics = []\n",
        "  seen_topics = set()\n",
        "  for topic in topics:\n",
        "    most_similar_topic = None\n",
        "    max_similarity = 0\n",
        "    for seen_topic in seen_topics:\n",
        "      similarity = np.dot(topic, seen_topic) / (np.linalg.norm(topic) * np.linalg.norm(seen_topic))\n",
        "      if similarity > max_similarity:\n",
        "        max_similarity = similarity\n",
        "        most_similar_topic = seen_topic\n",
        "    if max_similarity < threshold:\n",
        "      merged_topics.append(topic)\n",
        "      seen_topics.add(tuple(topic))  # Convert topic to hashable tuple for set\n",
        "    else:\n",
        "      # Skip adding similar topic (already merged)\n",
        "      pass\n",
        "  return merged_topics\n",
        "\n",
        "def find_optimal_num_topics(documents, max_topics=25):\n",
        "    print(\"Finding the optimal number of topics\")\n",
        "    document_matrix, vectorizer, tokenized_documents = customize_tfidf_vectorizer(documents)\n",
        "\n",
        "    coherence_values = []\n",
        "    for num_topics in range(2, max_topics + 1):\n",
        "        lda = LatentDirichletAllocation(n_components=num_topics, random_state=0)\n",
        "        lda.fit(document_matrix)\n",
        "        topics = lda.components_\n",
        "        coherence_values.append(umass_coherence(document_matrix, vectorizer.get_feature_names_out(), topics))\n",
        "\n",
        "    optimal_num_topics = np.argmax(coherence_values) + 2  # Adding 2 because the loop starts from 2\n",
        "    return optimal_num_topics\n",
        "\n",
        "def refine_similarity_with_word_embeddings(merged_topics, word2vec_model):\n",
        "    print(\"Refining similarity using word embeddings\")\n",
        "    # Use Word2Vec for semantic similarity\n",
        "    refined_topics = []\n",
        "    for topic in merged_topics:\n",
        "        if isinstance(topic, np.ndarray):  # Check if topic is a numpy array (vector)\n",
        "            topic_embedding = topic\n",
        "        else:\n",
        "            # Calculate centroid of the topic using Word2Vec embeddings\n",
        "            topic_embedding = np.mean([word2vec_model.wv[word] for word in topic], axis=0)\n",
        "        refined_topics.append(topic_embedding)\n",
        "    return refined_topics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbbrvUBV6EXE",
        "outputId": "816fc4a0-a577-40d0-dc09-e0b99747bc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_docx(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "\n",
        "    statements = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        # Tokenize paragraph into sentences\n",
        "        sentences = nltk.sent_tokenize(paragraph.text.strip())\n",
        "\n",
        "        # Add each sentence to the statements list\n",
        "        statements.extend(sentences)\n",
        "\n",
        "    return statements\n",
        "\n",
        "# Replace 'your_document.docx' with the actual path to your DOCX file\n",
        "docx_file_path = '/content/6683127-House-Rental-Contract-GERALDINE-GALINATO-v2-Page-1.pdf.docx'\n",
        "sentences = read_docx(docx_file_path)\n",
        "\n",
        "# Print the sentences\n",
        "for idx, sentence in enumerate(sentences, start=1):\n",
        "    print(f\"Sentence {idx}: {sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7SW2u3-XlEl",
        "outputId": "e29abfa7-11e6-40eb-c174-20006020f42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1: House Rental Contract\n",
            "Sentence 2: KNOWN ALL MEN BY THESE PRESENTS:\n",
            "Sentence 3: This House Rental Contract, made and entered into this 20th day of May 2007 at Manila by and between:\n",
            "Sentence 4: Antonio Levy S. Ingles.\n",
            "Sentence 5: Jr. and/or Mary Rose C. Ingles, of legal age, with residence and postal address at Unit 2006 EGI Taft Tower 2339 Taft Avenue, Malate, Manila, And herein referred to as the Owner(s),\n",
            "Sentence 6: — And —\n",
            "Sentence 7: GERALDINE O. GALINATO.\n",
            "Sentence 8: of legal age, with residence and postal address at 6 Manganese Road, Pilar Village, Las Pinas, Metro Manila, And herein referred to as the\n",
            "Sentence 9: Resident(s),\n",
            "Sentence 10: WITNESSETH:\n",
            "Sentence 11: In consideration of the agreements of the Resident(s), known as: GERALDINE O. GALINATO.\n",
            "Sentence 12: the Owner(s), known as: Antonio Levy S. Ingles.\n",
            "Sentence 13: Jr. and/or Mary Rose C. Ingles, hereby rent their the dwelling/house located at Lot 6, Block 20, Royal South Townhomes, Marcos Alvarez Avenue, Talon 5, Las Pinas City, Metro Manila for the period commencing on the 20th day of May, 2007, and monthly thereafter until the 20th day of May, 2008, at which time this Agreement is terminated.\n",
            "Sentence 14: Resident(s), in consideration of Owner(s) permitting them to occupy the above property, hereby agrees to the following terms:\n",
            "Sentence 15: RENT: To pay as rental the sum of SIX THOUSAND FIVE HUNDRED PESOS IP 6.500.001 per month, due and payable in advance from the 20th day of every month.\n",
            "Sentence 16: FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.\n",
            "Sentence 17: This Notice may be served if you have an outstanding balance from failure to pay your rent.\n",
            "Sentence 18: This Notice may also be served from being habitually late in paying your rent regardless of the balance owed.\n",
            "Sentence 19: Once the Notice to End Residential Tenancy is received, you will have a prescribed time to pay all of the amount overdue on your rent.\n",
            "Sentence 20: A three-dav grace period will be allowed for late payment.\n",
            "Sentence 21: Failure to pay the monthly rental within the grace period is subject to FIVE (5%) PERCENT interest per month of delay as penalty.\n",
            "Sentence 22: Habitual failure of the Resident(s) to pay within the prescribed time shall result in the Owner(s) taking immediate legal action to evict the Resident(s) from the premises and seize the security deposit.\n",
            "Sentence 23: SECURITY DEPOSIT: Resident(s) agrees to pay a deposit in the amount of SIX THOUSAND FIVE HUNDRED PESOS (P 6.500.001 to secure Resident(s)’s pledge of full compliance with the terms of this agreement.\n",
            "Sentence 24: Note: THE DEPOSIT MAY NOT BE USED BY TENANT TO PAY THE RENT DURING THE TENANCY.\n",
            "Sentence 25: The security deposit will be used at the end of the tenancy to compensate the Owner(s) for any damages or unpaid rent or charges, and will be repaired or replaced at Resident(s)’s expense with funds other than the deposit.\n",
            "Sentence 26: METHOD OF PAYMENT: The initial advance payment of rent and deposit under this contract be PAID IN CASH at least 7 days before the date of moving-in.\n",
            "Sentence 27: Thereafter, monthly rent payments must be paid by POST DATED CHECKS payable to ANTONIO LEVY S. INGLES.\n",
            "Sentence 28: JR. until a first check is dishonored and returned unpaid.\n",
            "Sentence 29: Regardless of cause, no other additional payments may afterwards be made by check.\n",
            "Sentence 30: Checks returned will not be redeposited.\n",
            "Sentence 31: The Resident(s) will be notified by a 3 day notice, and will be required to pay the amount due in cash.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_num_topics = find_optimal_num_topics(sentences)\n",
        "print(\"Optimal Number of Topics:\", optimal_num_topics)\n",
        "\n",
        "document_matrix, vectorizer, tokenized_documents = customize_tfidf_vectorizer(sentences)\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=optimal_num_topics, random_state=0)\n",
        "lda.fit(document_matrix)\n",
        "topics = lda.components_\n",
        "\n",
        "merged_topics = check_and_merge_topics(topics, threshold=0.9)\n",
        "\n",
        "word2vec_model = Word2Vec(tokenized_documents, min_count=1)  # Use tokenized_documents\n",
        "refined_topics = refine_similarity_with_word_embeddings(merged_topics, word2vec_model)\n",
        "\n",
        "for topic_idx, topic in enumerate(refined_topics):\n",
        "    print(\"Topic\", topic_idx + 1, \":\")\n",
        "    print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnz-Kpoj6YAM",
        "outputId": "b4443943-db5e-47f3-d7b7-5fd833dc8808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding the optimal number of topics\n",
            "Cleaning documents\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "umass coherence\n",
            "Optimal Number of Topics: 25\n",
            "Cleaning documents\n",
            "Checking and removing duplicate topics\n",
            "Refining similarity using word embeddings\n",
            "Topic 1 :\n",
            "['grace period', 'grace', 'geraldine galinato', 'geraldine', 'galinato', 'failure pay', 'failure', 'end residential', 'house rental', 'used']\n",
            "\n",
            "\n",
            "Topic 2 :\n",
            "['deposit', '20th day', '20th', 'contract', 'rent', 'cash', 'advance', 'paid', 'payment', 'day']\n",
            "\n",
            "\n",
            "Topic 3 :\n",
            "['geraldine', 'galinato', 'failure pay', 'failure', 'end residential', 'end', 'grace period', 'used', 'known', 'resident']\n",
            "\n",
            "\n",
            "Topic 4 :\n",
            "['used', 'pay', 'rental', 'failure', 'failure pay', 'period', 'monthly', 'grace period', 'grace', 'month']\n",
            "\n",
            "\n",
            "Topic 5 :\n",
            "['rental', '20th day', '20th', 'advance', 'payable', '6500001', 'thousand', 'thousand peso', 'peso', 'month']\n",
            "\n",
            "\n",
            "Topic 6 :\n",
            "['galinato', 'failure pay', 'failure', 'end residential', 'used', 'resident', 'owner', 'consideration', 'agrees', 'term']\n",
            "\n",
            "\n",
            "Topic 7 :\n",
            "['result', 'balance', 'notice served', 'rent', 'notice', 'pay', 'pay rent', 'served', 'failure', 'failure pay']\n",
            "\n",
            "\n",
            "Topic 8 :\n",
            "['geraldine', 'galinato', 'failure pay', 'failure', 'end residential', 'grace period', 'used', 'check', 'payment', 'regardless']\n",
            "\n",
            "\n",
            "Topic 9 :\n",
            "['galinato', 'failure pay', 'failure', 'end residential', 'used', 'payment', 'period', 'late', 'grace', 'grace period']\n",
            "\n",
            "\n",
            "Topic 10 :\n",
            "['monthly', '2007', 'day 2007', 'unpaid', 'deposit used', 'used', 'paid', 'payable', 'rent', 'deposit']\n",
            "\n",
            "\n",
            "Topic 11 :\n",
            "['failure', 'end residential', 'grace', 'rent', 'notice', 'served', 'regardless', 'late', 'balance', 'notice served']\n",
            "\n",
            "\n",
            "Topic 12 :\n",
            "['end residential', 'end', 'la', 'rent', 'pay', 'deposit', 'tenancy', 'pay rent', 'deposit used', 'used']\n",
            "\n",
            "\n",
            "Topic 13 :\n",
            "['day 2007', '20th day', '20th', 'manila', 'day', 'rental', 'contract', 'house rental', 'rental contract', 'house']\n",
            "\n",
            "\n",
            "Topic 14 :\n",
            "['monthly', 'check', 'payment', 'owner', 'known', 'ingles', 'antonio levy', 'levy ingles', 'levy', 'antonio']\n",
            "\n",
            "\n",
            "Topic 15 :\n",
            "['galinato', 'failure pay', 'failure', 'grace period', 'used', 'pay', 'resident', 'notice', 'day', 'cash']\n",
            "\n",
            "\n",
            "Topic 16 :\n",
            "['residence', 'referred', 'postal address', 'postal', 'manila referred', 'age residence', 'age', 'legal age', 'address', 'residence postal']\n",
            "\n",
            "\n",
            "Topic 17 :\n",
            "['consideration', 'owner', 'security', 'security deposit', 'agreement', 'deposit', 'galinato', 'geraldine', 'geraldine galinato', 'resident']\n",
            "\n",
            "\n",
            "Topic 18 :\n",
            "['notice', 'tenancy', 'time', 'end', 'residential', 'notice end', 'end residential', 'residential tenancy', 'prescribed time', 'prescribed']\n",
            "\n",
            "\n",
            "Topic 19 :\n",
            "['galinato', 'failure pay', 'failure', 'end residential', 'grace period', 'legal age', 'jr', 'unpaid', 'check', 'returned']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5ghxtXvc-7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def find_topic_anomalies(refined_topics, threshold=2.0):\n",
        "    \"\"\"\n",
        "    Identifies anomalies for each dimension (feature) across refined topics.\n",
        "\n",
        "    Args:\n",
        "        refined_topics (list): List of NumPy arrays representing individual topics.\n",
        "        threshold (float, optional): Threshold for z-score anomaly detection. Defaults to 2.0.\n",
        "\n",
        "    Returns:\n",
        "        list: List of lists, where each inner list contains anomaly indices for a dimension.\n",
        "    \"\"\"\n",
        "    # Convert the list of arrays to a 2D NumPy array\n",
        "    topic_values = np.vstack(refined_topics)\n",
        "\n",
        "    # Print shapes for debugging (optional)\n",
        "    print(f\"Shape of refined_topics: {refined_topics[0].shape}\")  # Assuming first element represents shape\n",
        "    print(f\"Shape of topic_values: {topic_values.shape}\")\n",
        "\n",
        "    # Calculate mean and standard deviation for each dimension across all topics\n",
        "    mean_values = topic_values.mean(axis=0)\n",
        "    std_values = topic_values.std(axis=0)\n",
        "\n",
        "    # Print mean and standard deviation for debugging (optional)\n",
        "    print(f\"Mean values: {mean_values}\")\n",
        "    print(f\"Standard deviation: {std_values}\")\n",
        "\n",
        "    # Identify anomalies for each dimension (feature)\n",
        "    anomalies_per_dimension = []\n",
        "    for dimension in range(topic_values.shape[1]):\n",
        "        z_scores = []\n",
        "        for topic_idx, value in enumerate(topic_values[:, dimension]):\n",
        "            # Ensure both mean and std are not zero to avoid division by zero\n",
        "            if std_values[dimension] != 0:\n",
        "                z_score = (value - mean_values[dimension]) / std_values[dimension]\n",
        "            else:\n",
        "                z_score = 0  # Handle cases where standard deviation is zero\n",
        "            z_scores.append((topic_idx, z_score))\n",
        "\n",
        "        anomalies = [topic_idx for topic_idx, z_score in z_scores if abs(z_score) > threshold]\n",
        "        anomalies_per_dimension.append(anomalies)\n",
        "\n",
        "    return anomalies_per_dimension\n",
        "\n",
        "\n",
        "anomalies_per_dimension = find_topic_anomalies(refined_topics)\n",
        "\n",
        "# Print the identified anomalies for each dimension\n",
        "for i, anomalies in enumerate(anomalies_per_dimension):\n",
        "    print(f\"Anomalies in Dimension {i + 1}:\", anomalies)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWsZLdj5YKCF",
        "outputId": "fa1f13a1-6ed8-4fe1-c3f3-b8f8bf47f412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of refined_topics: (94,)\n",
            "Shape of topic_values: (19, 94)\n",
            "Mean values: [0.0670607  0.08464082 0.08464082 0.06986765 0.0642455  0.07395067\n",
            " 0.0642455  0.0642455  0.08236469 0.08097621 0.06136587 0.06136587\n",
            " 0.10115609 0.10115609 0.06136587 0.08218178 0.08870157 0.14150862\n",
            " 0.08706906 0.09563563 0.11743902 0.0670607  0.13032622 0.08062689\n",
            " 0.08322377 0.07022779 0.10698366 0.09704232 0.09156677 0.09156677\n",
            " 0.09156677 0.08405646 0.08405646 0.08166303 0.08166303 0.11007132\n",
            " 0.08506608 0.06136587 0.13263302 0.06299049 0.06299049 0.08642897\n",
            " 0.07734833 0.0642455  0.10115609 0.10115609 0.08352255 0.0642455\n",
            " 0.06136587 0.06136587 0.06299049 0.06299049 0.0844244  0.08332373\n",
            " 0.12095573 0.07022779 0.08218178 0.11416016 0.077087   0.15490396\n",
            " 0.09243087 0.07269749 0.13223624 0.08948865 0.06986765 0.06299049\n",
            " 0.0642455  0.0642455  0.07349425 0.07349425 0.0642455  0.0954707\n",
            " 0.14744729 0.10433629 0.08166303 0.0642455  0.0642455  0.19700361\n",
            " 0.07022779 0.07022779 0.06991736 0.1080462  0.06136587 0.06136587\n",
            " 0.08455097 0.08455097 0.09076478 0.10010533 0.08097621 0.06986765\n",
            " 0.06986765 0.08824662 0.08494424 0.08062689]\n",
            "Standard deviation: [0.08175112 0.10334986 0.10334986 0.08708353 0.10286496 0.09990271\n",
            " 0.10286496 0.10286496 0.14392634 0.12401786 0.06241168 0.06241168\n",
            " 0.25946333 0.25946333 0.06241168 0.12305145 0.14553545 0.27003497\n",
            " 0.13799419 0.17415623 0.16197127 0.08175112 0.18481503 0.12015956\n",
            " 0.10052341 0.0888153  0.17224964 0.17909028 0.21877927 0.21877927\n",
            " 0.21877927 0.12946432 0.12946432 0.17676127 0.17676127 0.22674803\n",
            " 0.11827328 0.06241168 0.24344794 0.0676133  0.0676133  0.13565461\n",
            " 0.10910321 0.10286496 0.25946333 0.25946333 0.10714092 0.10286496\n",
            " 0.06241168 0.06241168 0.0676133  0.0676133  0.13067434 0.10398\n",
            " 0.16320774 0.0888153  0.12305145 0.14640726 0.10819522 0.1650921\n",
            " 0.15551195 0.09581763 0.18473038 0.12165732 0.08708353 0.0676133\n",
            " 0.10286496 0.10286496 0.09765636 0.09765636 0.10286496 0.16584989\n",
            " 0.14994279 0.16650929 0.17676127 0.10286496 0.10286496 0.3144626\n",
            " 0.0888153  0.0888153  0.08780249 0.2886956  0.06241168 0.06241168\n",
            " 0.13628991 0.13628991 0.15179776 0.1195769  0.12401786 0.08708353\n",
            " 0.08708353 0.09566802 0.1352541  0.12015956]\n",
            "Anomalies in Dimension 1: [1, 9]\n",
            "Anomalies in Dimension 2: [1, 4, 9]\n",
            "Anomalies in Dimension 3: [1, 4, 9]\n",
            "Anomalies in Dimension 4: [4, 16]\n",
            "Anomalies in Dimension 5: [15]\n",
            "Anomalies in Dimension 6: [1, 4]\n",
            "Anomalies in Dimension 7: [15]\n",
            "Anomalies in Dimension 8: [15]\n",
            "Anomalies in Dimension 9: [16]\n",
            "Anomalies in Dimension 10: [5]\n",
            "Anomalies in Dimension 11: [1, 16]\n",
            "Anomalies in Dimension 12: [1, 16]\n",
            "Anomalies in Dimension 13: [13]\n",
            "Anomalies in Dimension 14: [13]\n",
            "Anomalies in Dimension 15: [1, 16]\n",
            "Anomalies in Dimension 16: [6, 10]\n",
            "Anomalies in Dimension 17: [1, 14]\n",
            "Anomalies in Dimension 18: [18]\n",
            "Anomalies in Dimension 19: [5, 16]\n",
            "Anomalies in Dimension 20: [12]\n",
            "Anomalies in Dimension 21: [1, 14]\n",
            "Anomalies in Dimension 22: [1, 9]\n",
            "Anomalies in Dimension 23: [16]\n",
            "Anomalies in Dimension 24: [9, 11]\n",
            "Anomalies in Dimension 25: [9, 17]\n",
            "Anomalies in Dimension 26: [6, 17]\n",
            "Anomalies in Dimension 27: [6]\n",
            "Anomalies in Dimension 28: [6]\n",
            "Anomalies in Dimension 29: [16]\n",
            "Anomalies in Dimension 30: [16]\n",
            "Anomalies in Dimension 31: [16]\n",
            "Anomalies in Dimension 32: [3, 8]\n",
            "Anomalies in Dimension 33: [3, 8]\n",
            "Anomalies in Dimension 34: [12]\n",
            "Anomalies in Dimension 35: [12]\n",
            "Anomalies in Dimension 36: [13]\n",
            "Anomalies in Dimension 37: [18]\n",
            "Anomalies in Dimension 38: [1, 16]\n",
            "Anomalies in Dimension 39: [2]\n",
            "Anomalies in Dimension 40: [1, 15]\n",
            "Anomalies in Dimension 41: [1, 15]\n",
            "Anomalies in Dimension 42: [8, 10]\n",
            "Anomalies in Dimension 43: [15, 16]\n",
            "Anomalies in Dimension 44: [15]\n",
            "Anomalies in Dimension 45: [13]\n",
            "Anomalies in Dimension 46: [13]\n",
            "Anomalies in Dimension 47: [9, 15]\n",
            "Anomalies in Dimension 48: [15]\n",
            "Anomalies in Dimension 49: [1, 16]\n",
            "Anomalies in Dimension 50: [1, 16]\n",
            "Anomalies in Dimension 51: [1, 15]\n",
            "Anomalies in Dimension 52: [1, 15]\n",
            "Anomalies in Dimension 53: [3, 4]\n",
            "Anomalies in Dimension 54: [3, 9]\n",
            "Anomalies in Dimension 55: [6, 14]\n",
            "Anomalies in Dimension 56: [6, 17]\n",
            "Anomalies in Dimension 57: [6, 10]\n",
            "Anomalies in Dimension 58: [5, 16]\n",
            "Anomalies in Dimension 59: [1, 9]\n",
            "Anomalies in Dimension 60: [6]\n",
            "Anomalies in Dimension 61: [6, 11]\n",
            "Anomalies in Dimension 62: [4, 9]\n",
            "Anomalies in Dimension 63: [1, 7]\n",
            "Anomalies in Dimension 64: [3, 8]\n",
            "Anomalies in Dimension 65: [4, 16]\n",
            "Anomalies in Dimension 66: [1, 15]\n",
            "Anomalies in Dimension 67: [15]\n",
            "Anomalies in Dimension 68: [15]\n",
            "Anomalies in Dimension 69: [16, 17]\n",
            "Anomalies in Dimension 70: [16, 17]\n",
            "Anomalies in Dimension 71: [15]\n",
            "Anomalies in Dimension 72: [7, 10]\n",
            "Anomalies in Dimension 73: [9]\n",
            "Anomalies in Dimension 74: [12]\n",
            "Anomalies in Dimension 75: [12]\n",
            "Anomalies in Dimension 76: [15]\n",
            "Anomalies in Dimension 77: [15]\n",
            "Anomalies in Dimension 78: [2, 16]\n",
            "Anomalies in Dimension 79: [6, 17]\n",
            "Anomalies in Dimension 80: [6, 17]\n",
            "Anomalies in Dimension 81: [6, 16]\n",
            "Anomalies in Dimension 82: [18]\n",
            "Anomalies in Dimension 83: [1, 16]\n",
            "Anomalies in Dimension 84: [1, 16]\n",
            "Anomalies in Dimension 85: [16]\n",
            "Anomalies in Dimension 86: [16]\n",
            "Anomalies in Dimension 87: [6, 10]\n",
            "Anomalies in Dimension 88: [11]\n",
            "Anomalies in Dimension 89: [5]\n",
            "Anomalies in Dimension 90: [4, 16]\n",
            "Anomalies in Dimension 91: [4, 16]\n",
            "Anomalies in Dimension 92: [16, 17]\n",
            "Anomalies in Dimension 93: [9, 18]\n",
            "Anomalies in Dimension 94: [9, 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refined_topics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR1-9rYwc07d",
        "outputId": "3a8fd567-8b21-4845-d4da-ab07d86df777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.1, 0.2, 0.3, Ellipsis], dtype=object)]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def find_topic_anomalies(refined_topics, original_texts, threshold=2.0):\n",
        "    \"\"\"\n",
        "    Identifies anomalies for each dimension (feature) across refined topics.\n",
        "\n",
        "    Args:\n",
        "        refined_topics (list): List of NumPy arrays representing individual topics.\n",
        "        original_texts (list): List of original texts corresponding to the refined topics.\n",
        "        threshold (float, optional): Threshold for z-score anomaly detection. Defaults to 2.0.\n",
        "\n",
        "    Returns:\n",
        "        list: List of lists, where each inner list contains original texts for anomalies in a dimension.\n",
        "    \"\"\"\n",
        "    # Convert the list of arrays to a 2D NumPy array\n",
        "    topic_values = np.vstack(refined_topics)\n",
        "\n",
        "    # Calculate mean and standard deviation for each dimension across all topics\n",
        "    mean_values = topic_values.mean(axis=0)\n",
        "    std_values = topic_values.std(axis=0)\n",
        "\n",
        "    # Identify anomalies for each dimension (feature)\n",
        "    anomalies_per_dimension = []\n",
        "    for dimension in range(topic_values.shape[1]):\n",
        "        z_scores = []\n",
        "        for topic_idx, value in enumerate(topic_values[:, dimension]):\n",
        "            # Ensure both mean and std are not zero to avoid division by zero\n",
        "            if std_values[dimension] != 0:\n",
        "                z_score = (value - mean_values[dimension]) / std_values[dimension]\n",
        "            else:\n",
        "                z_score = 0  # Handle cases where standard deviation is zero\n",
        "            z_scores.append((topic_idx, z_score))\n",
        "\n",
        "        anomalies = [original_texts[topic_idx] for topic_idx, z_score in z_scores if abs(z_score) > threshold]\n",
        "        anomalies_per_dimension.append(anomalies)\n",
        "\n",
        "    return anomalies_per_dimension\n",
        "\n",
        "# Assuming 'sentences' is the original list of sentences corresponding to the refined topics\n",
        "anomalies_per_dimension = find_topic_anomalies(refined_topics, sentences)\n",
        "\n",
        "# Print the identified anomalies for each dimension\n",
        "for i, anomalies in enumerate(anomalies_per_dimension):\n",
        "    print(f\"Anomalies in Dimension {i + 1}:\", anomalies)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVr7scEXc5Gl",
        "outputId": "29a1825d-86b9-464f-8bc7-de099b34e3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anomalies in Dimension 1: ['KNOWN ALL MEN BY THESE PRESENTS:', 'WITNESSETH:']\n",
            "Anomalies in Dimension 2: ['KNOWN ALL MEN BY THESE PRESENTS:', 'Jr. and/or Mary Rose C. Ingles, of legal age, with residence and postal address at Unit 2006 EGI Taft Tower 2339 Taft Avenue, Malate, Manila, And herein referred to as the Owner(s),', 'WITNESSETH:']\n",
            "Anomalies in Dimension 3: ['KNOWN ALL MEN BY THESE PRESENTS:', 'Jr. and/or Mary Rose C. Ingles, of legal age, with residence and postal address at Unit 2006 EGI Taft Tower 2339 Taft Avenue, Malate, Manila, And herein referred to as the Owner(s),', 'WITNESSETH:']\n",
            "Anomalies in Dimension 4: ['Jr. and/or Mary Rose C. Ingles, of legal age, with residence and postal address at Unit 2006 EGI Taft Tower 2339 Taft Avenue, Malate, Manila, And herein referred to as the Owner(s),', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 5: ['FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 6: ['KNOWN ALL MEN BY THESE PRESENTS:', 'Jr. and/or Mary Rose C. Ingles, of legal age, with residence and postal address at Unit 2006 EGI Taft Tower 2339 Taft Avenue, Malate, Manila, And herein referred to as the Owner(s),']\n",
            "Anomalies in Dimension 7: ['FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 8: ['FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 9: ['This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 10: ['— And —']\n",
            "Anomalies in Dimension 11: ['KNOWN ALL MEN BY THESE PRESENTS:', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 12: ['KNOWN ALL MEN BY THESE PRESENTS:', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 13: ['Resident(s), in consideration of Owner(s) permitting them to occupy the above property, hereby agrees to the following terms:']\n",
            "Anomalies in Dimension 14: ['Resident(s), in consideration of Owner(s) permitting them to occupy the above property, hereby agrees to the following terms:']\n",
            "Anomalies in Dimension 15: ['KNOWN ALL MEN BY THESE PRESENTS:', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 16: ['GERALDINE O. GALINATO.', 'In consideration of the agreements of the Resident(s), known as: GERALDINE O. GALINATO.']\n",
            "Anomalies in Dimension 17: ['KNOWN ALL MEN BY THESE PRESENTS:', 'RENT: To pay as rental the sum of SIX THOUSAND FIVE HUNDRED PESOS IP 6.500.001 per month, due and payable in advance from the 20th day of every month.']\n",
            "Anomalies in Dimension 18: ['Once the Notice to End Residential Tenancy is received, you will have a prescribed time to pay all of the amount overdue on your rent.']\n",
            "Anomalies in Dimension 19: ['— And —', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 20: ['Jr. and/or Mary Rose C. Ingles, hereby rent their the dwelling/house located at Lot 6, Block 20, Royal South Townhomes, Marcos Alvarez Avenue, Talon 5, Las Pinas City, Metro Manila for the period commencing on the 20th day of May, 2007, and monthly thereafter until the 20th day of May, 2008, at which time this Agreement is terminated.']\n",
            "Anomalies in Dimension 21: ['KNOWN ALL MEN BY THESE PRESENTS:', 'RENT: To pay as rental the sum of SIX THOUSAND FIVE HUNDRED PESOS IP 6.500.001 per month, due and payable in advance from the 20th day of every month.']\n",
            "Anomalies in Dimension 22: ['KNOWN ALL MEN BY THESE PRESENTS:', 'WITNESSETH:']\n",
            "Anomalies in Dimension 23: ['This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 24: ['WITNESSETH:', 'the Owner(s), known as: Antonio Levy S. Ingles.']\n",
            "Anomalies in Dimension 25: ['WITNESSETH:', 'This Notice may also be served from being habitually late in paying your rent regardless of the balance owed.']\n",
            "Anomalies in Dimension 26: ['GERALDINE O. GALINATO.', 'This Notice may also be served from being habitually late in paying your rent regardless of the balance owed.']\n",
            "Anomalies in Dimension 27: ['GERALDINE O. GALINATO.']\n",
            "Anomalies in Dimension 28: ['GERALDINE O. GALINATO.']\n",
            "Anomalies in Dimension 29: ['This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 30: ['This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 31: ['This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 32: ['Antonio Levy S. Ingles.', 'Resident(s),']\n",
            "Anomalies in Dimension 33: ['Antonio Levy S. Ingles.', 'Resident(s),']\n",
            "Anomalies in Dimension 34: ['Jr. and/or Mary Rose C. Ingles, hereby rent their the dwelling/house located at Lot 6, Block 20, Royal South Townhomes, Marcos Alvarez Avenue, Talon 5, Las Pinas City, Metro Manila for the period commencing on the 20th day of May, 2007, and monthly thereafter until the 20th day of May, 2008, at which time this Agreement is terminated.']\n",
            "Anomalies in Dimension 35: ['Jr. and/or Mary Rose C. Ingles, hereby rent their the dwelling/house located at Lot 6, Block 20, Royal South Townhomes, Marcos Alvarez Avenue, Talon 5, Las Pinas City, Metro Manila for the period commencing on the 20th day of May, 2007, and monthly thereafter until the 20th day of May, 2008, at which time this Agreement is terminated.']\n",
            "Anomalies in Dimension 36: ['Resident(s), in consideration of Owner(s) permitting them to occupy the above property, hereby agrees to the following terms:']\n",
            "Anomalies in Dimension 37: ['Once the Notice to End Residential Tenancy is received, you will have a prescribed time to pay all of the amount overdue on your rent.']\n",
            "Anomalies in Dimension 38: ['KNOWN ALL MEN BY THESE PRESENTS:', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 39: ['This House Rental Contract, made and entered into this 20th day of May 2007 at Manila by and between:']\n",
            "Anomalies in Dimension 40: ['KNOWN ALL MEN BY THESE PRESENTS:', 'FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 41: ['KNOWN ALL MEN BY THESE PRESENTS:', 'FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 42: ['Resident(s),', 'In consideration of the agreements of the Resident(s), known as: GERALDINE O. GALINATO.']\n",
            "Anomalies in Dimension 43: ['FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 44: ['FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 45: ['Resident(s), in consideration of Owner(s) permitting them to occupy the above property, hereby agrees to the following terms:']\n",
            "Anomalies in Dimension 46: ['Resident(s), in consideration of Owner(s) permitting them to occupy the above property, hereby agrees to the following terms:']\n",
            "Anomalies in Dimension 47: ['WITNESSETH:', 'FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 48: ['FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 49: ['KNOWN ALL MEN BY THESE PRESENTS:', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 50: ['KNOWN ALL MEN BY THESE PRESENTS:', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 51: ['KNOWN ALL MEN BY THESE PRESENTS:', 'FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 52: ['KNOWN ALL MEN BY THESE PRESENTS:', 'FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 53: ['Antonio Levy S. Ingles.', 'Jr. and/or Mary Rose C. Ingles, of legal age, with residence and postal address at Unit 2006 EGI Taft Tower 2339 Taft Avenue, Malate, Manila, And herein referred to as the Owner(s),']\n",
            "Anomalies in Dimension 54: ['Antonio Levy S. Ingles.', 'WITNESSETH:']\n",
            "Anomalies in Dimension 55: ['GERALDINE O. GALINATO.', 'RENT: To pay as rental the sum of SIX THOUSAND FIVE HUNDRED PESOS IP 6.500.001 per month, due and payable in advance from the 20th day of every month.']\n",
            "Anomalies in Dimension 56: ['GERALDINE O. GALINATO.', 'This Notice may also be served from being habitually late in paying your rent regardless of the balance owed.']\n",
            "Anomalies in Dimension 57: ['GERALDINE O. GALINATO.', 'In consideration of the agreements of the Resident(s), known as: GERALDINE O. GALINATO.']\n",
            "Anomalies in Dimension 58: ['— And —', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 59: ['KNOWN ALL MEN BY THESE PRESENTS:', 'WITNESSETH:']\n",
            "Anomalies in Dimension 60: ['GERALDINE O. GALINATO.']\n",
            "Anomalies in Dimension 61: ['GERALDINE O. GALINATO.', 'the Owner(s), known as: Antonio Levy S. Ingles.']\n",
            "Anomalies in Dimension 62: ['Jr. and/or Mary Rose C. Ingles, of legal age, with residence and postal address at Unit 2006 EGI Taft Tower 2339 Taft Avenue, Malate, Manila, And herein referred to as the Owner(s),', 'WITNESSETH:']\n",
            "Anomalies in Dimension 63: ['KNOWN ALL MEN BY THESE PRESENTS:', 'of legal age, with residence and postal address at 6 Manganese Road, Pilar Village, Las Pinas, Metro Manila, And herein referred to as the']\n",
            "Anomalies in Dimension 64: ['Antonio Levy S. Ingles.', 'Resident(s),']\n",
            "Anomalies in Dimension 65: ['Jr. and/or Mary Rose C. Ingles, of legal age, with residence and postal address at Unit 2006 EGI Taft Tower 2339 Taft Avenue, Malate, Manila, And herein referred to as the Owner(s),', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 66: ['KNOWN ALL MEN BY THESE PRESENTS:', 'FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 67: ['FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 68: ['FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 69: ['This Notice may be served if you have an outstanding balance from failure to pay your rent.', 'This Notice may also be served from being habitually late in paying your rent regardless of the balance owed.']\n",
            "Anomalies in Dimension 70: ['This Notice may be served if you have an outstanding balance from failure to pay your rent.', 'This Notice may also be served from being habitually late in paying your rent regardless of the balance owed.']\n",
            "Anomalies in Dimension 71: ['FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 72: ['of legal age, with residence and postal address at 6 Manganese Road, Pilar Village, Las Pinas, Metro Manila, And herein referred to as the', 'In consideration of the agreements of the Resident(s), known as: GERALDINE O. GALINATO.']\n",
            "Anomalies in Dimension 73: ['WITNESSETH:']\n",
            "Anomalies in Dimension 74: ['Jr. and/or Mary Rose C. Ingles, hereby rent their the dwelling/house located at Lot 6, Block 20, Royal South Townhomes, Marcos Alvarez Avenue, Talon 5, Las Pinas City, Metro Manila for the period commencing on the 20th day of May, 2007, and monthly thereafter until the 20th day of May, 2008, at which time this Agreement is terminated.']\n",
            "Anomalies in Dimension 75: ['Jr. and/or Mary Rose C. Ingles, hereby rent their the dwelling/house located at Lot 6, Block 20, Royal South Townhomes, Marcos Alvarez Avenue, Talon 5, Las Pinas City, Metro Manila for the period commencing on the 20th day of May, 2007, and monthly thereafter until the 20th day of May, 2008, at which time this Agreement is terminated.']\n",
            "Anomalies in Dimension 76: ['FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 77: ['FAILURE TO PAY ON TIME: Failure to pay the rent will result in being served a Notice to End Residential Tenancy.']\n",
            "Anomalies in Dimension 78: ['This House Rental Contract, made and entered into this 20th day of May 2007 at Manila by and between:', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 79: ['GERALDINE O. GALINATO.', 'This Notice may also be served from being habitually late in paying your rent regardless of the balance owed.']\n",
            "Anomalies in Dimension 80: ['GERALDINE O. GALINATO.', 'This Notice may also be served from being habitually late in paying your rent regardless of the balance owed.']\n",
            "Anomalies in Dimension 81: ['GERALDINE O. GALINATO.', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 82: ['Once the Notice to End Residential Tenancy is received, you will have a prescribed time to pay all of the amount overdue on your rent.']\n",
            "Anomalies in Dimension 83: ['KNOWN ALL MEN BY THESE PRESENTS:', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 84: ['KNOWN ALL MEN BY THESE PRESENTS:', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 85: ['This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 86: ['This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 87: ['GERALDINE O. GALINATO.', 'In consideration of the agreements of the Resident(s), known as: GERALDINE O. GALINATO.']\n",
            "Anomalies in Dimension 88: ['the Owner(s), known as: Antonio Levy S. Ingles.']\n",
            "Anomalies in Dimension 89: ['— And —']\n",
            "Anomalies in Dimension 90: ['Jr. and/or Mary Rose C. Ingles, of legal age, with residence and postal address at Unit 2006 EGI Taft Tower 2339 Taft Avenue, Malate, Manila, And herein referred to as the Owner(s),', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 91: ['Jr. and/or Mary Rose C. Ingles, of legal age, with residence and postal address at Unit 2006 EGI Taft Tower 2339 Taft Avenue, Malate, Manila, And herein referred to as the Owner(s),', 'This Notice may be served if you have an outstanding balance from failure to pay your rent.']\n",
            "Anomalies in Dimension 92: ['This Notice may be served if you have an outstanding balance from failure to pay your rent.', 'This Notice may also be served from being habitually late in paying your rent regardless of the balance owed.']\n",
            "Anomalies in Dimension 93: ['WITNESSETH:', 'Once the Notice to End Residential Tenancy is received, you will have a prescribed time to pay all of the amount overdue on your rent.']\n",
            "Anomalies in Dimension 94: ['WITNESSETH:', 'the Owner(s), known as: Antonio Levy S. Ingles.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HtKVup35m2uv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}